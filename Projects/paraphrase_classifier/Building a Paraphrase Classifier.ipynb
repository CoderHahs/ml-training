{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Paraphrase Classifier\n",
    "\n",
    "This is an assignment for a Virtual Assistants course done in February 2022.\n",
    "\n",
    "The goal of this assignment is to create a simple paraphrase classifier that should output yes/no as classification for a paraphrase given two sentence inputs.\n",
    "\n",
    "The dataset to train and test the classifier can be found here: https://github.com/cocoxu/SemEval-PIT2015. The dataset was used for an internataional competition at SemEval 2015, called *Paraphrase and Semantic Similarity in Twitter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./SemEval-PIT2015-master/data/SemEval-PIT2015-github/SemEval-PIT2015-github/data/train.data\", sep='\\t', names=['Topic_Id', 'Topic_Name', 'Sent_1', 'Sent_2', 'Label', 'Sent_1_tag', 'Sent_2_tag'])\n",
    "dev_data = pd.read_csv(\"./SemEval-PIT2015-master/data/SemEval-PIT2015-github/SemEval-PIT2015-github/data/dev.data\", sep='\\t', names=['Topic_Id', 'Topic_Name', 'Sent_1', 'Sent_2', 'Label', 'Sent_1_tag', 'Sent_2_tag'])\n",
    "test_data = pd.read_csv(\"./SemEval-PIT2015-master/data/SemEval-PIT2015-github/SemEval-PIT2015-github/data/test.data\", sep='\\t', names=['Topic_Id', 'Topic_Name', 'Sent_1', 'Sent_2', 'Label', 'Sent_1_tag', 'Sent_2_tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the \"Label\" column to generate new columns \"Class\", \"Positive votes\", \"Negative Votes\"\n",
    "\n",
    "Assumptions made:\n",
    "- A majority vote in the \"Label\" column is what generates the \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "p_votes = []\n",
    "n_votes = []\n",
    "for row in train_data.iterrows():\n",
    "    row = row[1]\n",
    "    p_votes.append(row['Label'][1])\n",
    "    n_votes.append(row['Label'][4])\n",
    "    if (int(row['Label'][1]) > int(row['Label'][4])):\n",
    "        c.append(\"P\")\n",
    "    else:\n",
    "        c.append(\"NP\")\n",
    "        \n",
    "train_data['Class'] = c\n",
    "train_data['Positive votes'] = p_votes\n",
    "train_data['Negative votes'] = n_votes\n",
    "\n",
    "c = []\n",
    "p_votes = []\n",
    "n_votes = []\n",
    "for row in dev_data.iterrows():\n",
    "    row = row[1]\n",
    "    p_votes.append(row['Label'][1])\n",
    "    n_votes.append(row['Label'][4])\n",
    "    if (int(row['Label'][1]) > int(row['Label'][4])):\n",
    "        c.append(\"P\")\n",
    "    else:\n",
    "        c.append(\"NP\")\n",
    "        \n",
    "dev_data['Class'] = c\n",
    "dev_data['Positive votes'] = p_votes\n",
    "dev_data['Negative votes'] = n_votes\n",
    "\n",
    "c = []\n",
    "for row in test_data.iterrows():\n",
    "    row = row[1]\n",
    "    if (int(row['Label']) > 2):\n",
    "        c.append(\"P\")\n",
    "    else:\n",
    "        c.append(\"NP\")\n",
    "        \n",
    "test_data['Class'] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a baseline algorithm\n",
    "\n",
    "Our baseline algorithm can be simple. For this approach the baseline algorithm will look at how many words match between the two sentence sets. If 50% or more of the words match then we can classify them as \"paraphrase\" and if they don't then we classify them as \"non-paraphrase\". Each sentence's characters will be replaced by its lower form, and then split into words.\n",
    "\n",
    "We'll evaluate results using the Dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for row in dev_data.iterrows():\n",
    "    row = row[1]\n",
    "    words1 = set(row['Sent_1'].lower().split())\n",
    "    words2 = set(row['Sent_2'].lower().split())\n",
    "    same = words1.intersection(words2)\n",
    "    score = 2*len(same)/(len(words1) + len(words2))\n",
    "    if score >= 0.5:\n",
    "        pred.append('P')\n",
    "    else:\n",
    "        pred.append('NP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the precision and recall scores for our prediction values when compared to the Dev Set\n",
    "\n",
    "Precision and recall can be calculated like so:\n",
    "\n",
    "![Image](https://miro.medium.com/max/444/1*7J08ekAwupLBegeUI8muHA.png)\n",
    "\n",
    "Source: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9?gi=2925b9472506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6976\n",
      "Recall:  0.2965986394557823\n",
      "Accuracy:  0.7412735350116353\n"
     ]
    }
   ],
   "source": [
    "actual = dev_data['Class'].tolist()\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "acc = 0\n",
    "for pair in zip(pred, actual):\n",
    "#     print(pair[0], pair[1])\n",
    "    if pair[0] == 'P' and pair[0] == pair[1]:\n",
    "        tp += 1\n",
    "    elif pair[0] == 'NP' and pair[0] != pair[1]:\n",
    "        fn += 1\n",
    "    elif pair[0] == 'P' and pair[0] != pair[1]:\n",
    "        fp += 1\n",
    "        \n",
    "    if pair[0] == pair[1]:\n",
    "        acc += 1\n",
    "    \n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "acc = acc / len(actual)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results found for precision, recall and accuracy, we can see our baseline model works pretty well considering how simple the approach is. \n",
    "\n",
    "Recall seems to be the worst performing, which would mean we have a large number of false negatives. \n",
    "\n",
    "Let's try a different approach and see if that gets better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a classification model\n",
    "\n",
    "Now, we can try using a simple classification algorithm from sklearn and see if that is a better approach. \n",
    "\n",
    "We'll use a similar approach of splitting each sentence input into words. We'll generate a vector using a technique known as Bag of Words and use that as features for the classification algorithm. We can use a KNN Classifier to help perform the classification.\n",
    "\n",
    "Source: https://www.mygreatlearning.com/blog/bag-of-words/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVec = CountVectorizer()\n",
    "sentences = train_data['Sent_1'].tolist() + train_data['Sent_2'].tolist()\n",
    "count_data = CountVec.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_sent1 = CountVec.transform(train_data['Sent_1'].tolist())\n",
    "transformed_sent2 = CountVec.transform(train_data['Sent_2'].tolist())\n",
    "\n",
    "train_data['T_Sent_1'] = transformed_sent1\n",
    "train_data['T_Sent_2'] = transformed_sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "data = np.add(transformed_sent1.toarray(),transformed_sent2.toarray())\n",
    "X = pd.DataFrame(data,columns=CountVec.get_feature_names())\n",
    "y = train_data[['Class']]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=, random_state=1110)\n",
    "clf.fit(X, y.values.ravel())\n",
    "# score = clf.score(X_test, y_test.values.ravel())\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model trained, we can test it on Dev Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_sent1 = CountVec.transform(dev_data['Sent_1'].tolist())\n",
    "transformed_sent2 = CountVec.transform(dev_data['Sent_2'].tolist())\n",
    "data = np.add(transformed_sent1.toarray(),transformed_sent2.toarray())\n",
    "X = pd.DataFrame(data,columns=CountVec.get_feature_names())\n",
    "# y = dev_data[['Class']]\n",
    "# score = clf.score(X, y.values.ravel())\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.31746031746031744\n",
      "Recall:  0.05442176870748299\n",
      "Accuracy:  0.6695578591072562\n"
     ]
    }
   ],
   "source": [
    "actual = dev_data['Class'].tolist()\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "acc = 0\n",
    "for pair in zip(predictions, actual):\n",
    "#     print(pair[0], pair[1])\n",
    "    if pair[0] == 'P' and pair[0] == pair[1]:\n",
    "        tp += 1\n",
    "    elif pair[0] == 'NP' and pair[0] != pair[1]:\n",
    "        fn += 1\n",
    "    elif pair[0] == 'P' and pair[0] != pair[1]:\n",
    "        fp += 1\n",
    "        \n",
    "    if pair[0] == pair[1]:\n",
    "        acc += 1\n",
    "    \n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "acc = acc / len(actual)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, we observe that this new approach is worse than the baseline approach. Precision is half of what it was for the baseline, and recall is 1/6. Overall accuracy decreased by approximately 7%.\n",
    "\n",
    "A potential reason could be that the vector representation of each sentence only showed small differences between two inputs, as there were over 8000 features.\n",
    "\n",
    "A solution to this could be to remove stop words (like 'a', 'at', 'to', etc.). This will reduce the features and focus on words that matter between sentences.\n",
    "\n",
    "## Improving using stopwords\n",
    "\n",
    "For this all we need to do is make our CountVectorizer omit stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVec = CountVectorizer(stop_words='english')\n",
    "sentences = train_data['Sent_1'].tolist() + train_data['Sent_2'].tolist()\n",
    "count_data = CountVec.fit(sentences)\n",
    "\n",
    "transformed_sent1 = CountVec.transform(train_data['Sent_1'].tolist())\n",
    "transformed_sent2 = CountVec.transform(train_data['Sent_2'].tolist())\n",
    "\n",
    "train_data['T_Sent_1'] = transformed_sent1\n",
    "train_data['T_Sent_2'] = transformed_sent2\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "data = np.add(transformed_sent1.toarray(),transformed_sent2.toarray())\n",
    "X = pd.DataFrame(data,columns=CountVec.get_feature_names())\n",
    "y = train_data[['Class']]\n",
    "clf.fit(X, y.values.ravel())\n",
    "\n",
    "transformed_sent1 = CountVec.transform(dev_data['Sent_1'].tolist())\n",
    "transformed_sent2 = CountVec.transform(dev_data['Sent_2'].tolist())\n",
    "data = np.add(transformed_sent1.toarray(),transformed_sent2.toarray())\n",
    "X = pd.DataFrame(data,columns=CountVec.get_feature_names())\n",
    "\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.518348623853211\n",
      "Recall:  0.07687074829931972\n",
      "Accuracy:  0.6907129257457161\n"
     ]
    }
   ],
   "source": [
    "actual = dev_data['Class'].tolist()\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "acc = 0\n",
    "for pair in zip(predictions, actual):\n",
    "#     print(pair[0], pair[1])\n",
    "    if pair[0] == 'P' and pair[0] == pair[1]:\n",
    "        tp += 1\n",
    "    elif pair[0] == 'NP' and pair[0] != pair[1]:\n",
    "        fn += 1\n",
    "    elif pair[0] == 'P' and pair[0] != pair[1]:\n",
    "        fp += 1\n",
    "        \n",
    "    if pair[0] == pair[1]:\n",
    "        acc += 1\n",
    "    \n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "acc = acc / len(actual)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there has been improvement to all 3 evaluation metrics, with the most improvement being seen for precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
